# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ww1vh0P1l8XGWQf-G7wk3OLGK1It3qO-
"""

!pip install ultralytics

!pip install deep-sort-realtime

import cv2
import numpy as np
from ultralytics import YOLO
from deep_sort_realtime.deepsort_tracker import DeepSort
import math
from collections import defaultdict
from enum import Enum

class ExitZone(Enum):
    TOP = 1
    BOTTOM = 2
    LEFT = 3
    RIGHT = 4
    NONE = 5

BORDER_MARGIN = 50
AVAILABLE_ID_TTL_FRAMES = 150

def get_exit_zone(bbox, frame_width, frame_height):
    x1, y1, x2, y2 = bbox
    center_x = (x1 + x2) / 2

    if center_x < BORDER_MARGIN:
        return ExitZone.LEFT
    elif center_x > frame_width - BORDER_MARGIN:
        return ExitZone.RIGHT
    elif y1 < BORDER_MARGIN:
        return ExitZone.TOP
    elif y2 > frame_height - BORDER_MARGIN:
        return ExitZone.BOTTOM
    return ExitZone.NONE

def run_full_tracking_pipeline(video_path, model_path, params, output_suffix="tuned"):
    print(f"--- Running Tracking Pipeline on {video_path} with parameters: {params} ---")

    print(f"Loading YOLO model from: {model_path}")
    model = YOLO(model_path)

    print(f"Opening video file: {video_path}")
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Error opening video: {video_path}")
        return

    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)

    output_path = f'output_reid_final_{output_suffix}.mp4'
    out_video = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))

    tracker = DeepSort(
        max_age=params["max_age"],
        n_init=params["n_init"],
        max_cosine_distance=params["max_cosine_distance"],
        max_iou_distance=params["max_iou_distance"]
    )

    frame_num = 0
    prev_frame_active_tracks = {}
    available_ids = defaultdict(list)
    id_map = {}

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        frame_num += 1
        if frame_num % 100 == 0:
            print(f"  Processing frame {frame_num}...")

        results = model(frame, conf=params["conf_threshold"], verbose=False)
        detections = [
            (det[:4].tolist(), det[4].item(), model.names[int(det[5])])
            for det in results[0].boxes.data
            if model.names[int(det[5])] == 'player'
        ]

        tracks = tracker.update_tracks(detections, frame=frame)

        current_frame_confirmed_tracks = {}
        unconfirmed_new_tracks = []

        for track in tracks:
            if track.is_confirmed():
                current_frame_confirmed_tracks[track.track_id] = track.to_ltrb()
            elif track.time_since_update == 0:
                unconfirmed_new_tracks.append(track)

        prev_ids = set(prev_frame_active_tracks.keys())
        current_ids = set(current_frame_confirmed_tracks.keys())
        newly_lost_ids = prev_ids - current_ids

        for lost_id in newly_lost_ids:
            last_bbox = prev_frame_active_tracks[lost_id]
            exit_zone = get_exit_zone(last_bbox, frame_width, frame_height)
            if exit_zone != ExitZone.NONE:
                original_id = id_map.get(lost_id, lost_id)
                print(f"Frame {frame_num}: Player {original_id} lost near {exit_zone}. Adding to available pool.")
                available_ids[exit_zone].append({'id': original_id, 'frame': frame_num})

        for new_track in unconfirmed_new_tracks:
            entry_zone = get_exit_zone(new_track.to_ltrb(), frame_width, frame_height)
            if entry_zone != ExitZone.NONE and available_ids[entry_zone]:
                best_candidate = available_ids[entry_zone].pop(-1)
                old_id = best_candidate['id']
                new_id = new_track.track_id
                print(f"Frame {frame_num}: New player (temp ID {new_id}) appeared near {entry_zone}. Re-assigning to old ID {old_id}.")
                id_map[new_id] = old_id

        for zone in list(available_ids.keys()):
            available_ids[zone] = [
                info for info in available_ids[zone]
                if frame_num - info['frame'] < AVAILABLE_ID_TTL_FRAMES
            ]

        active_track_count = 0
        for track in tracks:
            if not track.is_confirmed():
                continue

            active_track_count += 1
            track_id = track.track_id
            display_id = id_map.get(track_id, track_id)
            ltrb = track.to_ltrb()
            x1, y1, x2, y2 = map(int, ltrb)

            label = f"Player {display_id}"
            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)

        prev_frame_active_tracks = current_frame_confirmed_tracks

        info_text = f"Frame: {frame_num} | Active Players: {active_track_count}"
        cv2.putText(frame, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

        y_offset = 0
        for i, info in enumerate(available_ids[ExitZone.LEFT]):
            display_text = f"Lost: {info['id']}"
            y_pos = (frame_height // 3) + y_offset
            cv2.putText(frame, display_text, (10, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            y_offset += 30

        y_offset = 0
        for i, info in enumerate(available_ids[ExitZone.RIGHT]):
            display_text = f"Lost: {info['id']}"
            (text_width, _), _ = cv2.getTextSize(display_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)
            y_pos = (frame_height // 3) + y_offset
            cv2.putText(frame, display_text, (frame_width - text_width - 10, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            y_offset += 30

        out_video.write(frame)

    cap.release()
    out_video.release()
    print(f"Done processing {video_path}! Output saved to {output_path}")
    print("----------------------------------------------------------")

VIDEO_PATH_TUNING = "/content/15sec_input_720p.mp4"
VIDEO_PATH_GENERALIZATION = "/content/15sec_input_720p.mp4"
MODEL_PATH = "best.pt"

optimal_params = {
    "conf_threshold": 0.7,
    "max_age": 60,
    "n_init": 2,
    "max_cosine_distance": 0.6,
    "max_iou_distance": 0.5
}

run_full_tracking_pipeline(
    VIDEO_PATH_TUNING,
    MODEL_PATH,
    optimal_params,
    output_suffix="reid_final"
)

